# -*- coding: utf-8 -*-
"""iCloud+ Prices.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yLLFeciCmg9ANPmTWzaJz9KkcyPKIAI8
"""

!pip -q install requests beautifulsoup4 lxml pandas openpyxl

# --- Config ---
SAVE_TO_DRIVE = False   # True = save to Google Drive (/MyDrive/iCloudPlus)
DOWNLOAD_FILES = True   # True = prompt browser downloads if not saving to Drive

# --- Imports ---
import re, math
from pathlib import Path
from typing import List, Dict, Any
import requests, pandas as pd
from bs4 import BeautifulSoup

# --- Output location (Colab-aware) ---
IN_COLAB = False
try:
    import google.colab  # type: ignore
    IN_COLAB = True
except Exception:
    pass

if SAVE_TO_DRIVE and IN_COLAB:
    from google.colab import drive  # type: ignore
    drive.mount('/content/drive')
    OUT_DIR = Path('/content/drive/MyDrive/iCloudPlus')
else:
    OUT_DIR = Path('/content')

OUT_DIR.mkdir(parents=True, exist_ok=True)
OUT_XLSX = OUT_DIR / 'icloud_plus_pricing.xlsx'
OUT_CSV  = OUT_DIR / 'icloud_plus_pricing.csv'

# --- Constants ---
URL = "https://support.apple.com/en-gb/108047"
HEADERS = {
    "User-Agent": ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                   "AppleWebKit/537.36 (KHTML, like Gecko) "
                   "Chrome/124.0 Safari/537.36"),
    "Accept-Language": "en-GB,en;q=0.9",
}

# --- Helpers ---
def norm(s: str) -> str:
    if not s:
        return ""
    s = (s.replace("\xa0", " ").replace("\u202f", " ").replace("\u2009", " ")
           .replace("\u200b", "").replace("\u200c", "").replace("\u200d", "")
           .replace("\ufeff", "").replace("\u00ad", "").replace("\u00ac", " "))
    s = s.replace("–", "-").replace("—", "-")
    return re.sub(r"\s+", " ", s).strip()

COUNTRY_RE = re.compile(
    r"""
    ^(?P<country>.+?)\s*(?:\d+(?:,\d+)*)?\s*
    \((?P<ccy>[A-Z]{2,5}|Euro)\)\s*(?:\d+(?:,\d+)*)?\s*$
    """, re.VERBOSE
)

PLAN_RE = re.compile(
    r"""^\s*(?P<size>\d+)\s*[^A-Za-z0-9]{0,5}\s*(?P<unit>GB|TB)\s*[:\-]?\s*(?P<price>.+?)\s*$""",
    re.IGNORECASE
)

NUM_TOKEN = re.compile(r"\d[\d.,]*")

CURRENCY_HINTS = {
    "Euro": ["€", "EUR"], "USD": ["$", "USD"], "CAD": ["$", "CAD"], "AUD": ["$", "AUD"],
    "NZD": ["$", "NZD"], "HKD": ["HK$", "HKD"], "SGD": ["S$", "SGD"], "TWD": ["NT$", "TWD"],
    "ILS": ["₪", "ILS"], "QAR": ["﷼", "QAR"], "SAR": ["﷼", "SAR"], "JPY": ["¥", "JPY"],
    "CNY": ["¥", "CNY"], "KRW": ["₩", "KRW"], "VND": ["₫", "VND"], "ZAR": ["R", "ZAR"],
    "CHF": ["CHF", "Fr"], "NOK": ["kr", "NOK"], "SEK": ["kr", "SEK"], "DKK": ["kr", "DKK"],
    "PLN": ["zł", "PLN"], "HUF": ["Ft", "HUF"], "CZK": ["Kč", "CZK"], "RUB": ["p.", "₽", "RUB"],
    "PEN": ["S/", "PEN"], "MXN": ["$", "MXN"], "CLP": ["$", "CLP"], "COP": ["$", "COP"],
    "BRL": ["R$", "BRL"], "MYR": ["RM", "MYR"], "THB": ["฿", "THB"], "TRY": ["TL", "TRY"],
    "AED": ["AED"], "EGP": ["£", "EGP"], "NGN": ["₦", "NGN"], "KZT": ["₸", "KZT"], "TZS": ["TSh", "TZS"],
}

def standardize_plan(size: str, unit: str) -> str:
    return f"{int(size)} {unit.upper()}"

def parse_numeric_price(s: str) -> float:
    if not s: return math.nan
    s = norm(s)
    s = re.sub(r"^[^\d]+", "", s)  # strip leading currency text/symbols like "S/."
    m = NUM_TOKEN.search(s)
    if not m: return math.nan
    token = m.group(0)

    if "," in token and "." in token:
        last_c, last_d = token.rfind(","), token.rfind(".")
        dec = "," if last_c > last_d else "."
        thou = "." if dec == "," else ","
        token = token.replace(thou, "").replace(dec, ".")
    elif "," in token:
        parts = token.split(",")
        token = token.replace(",", ".") if len(parts[-1]) == 2 else token.replace(",", "")
    elif "." in token:
        parts = token.split(".")
        if len(parts) > 2 and all(len(p) == 3 for p in parts[1:]) and len(parts[-1]) in (3, 0):
            token = "".join(parts)

    try:
        return float(token)
    except Exception:
        return math.nan

# --- Scrape ---
def fetch_html() -> str:
    r = requests.get(URL, headers=HEADERS, timeout=30)
    r.raise_for_status()
    return r.text

def parse_all_rows(html: str) -> List[Dict[str, Any]]:
    soup = BeautifulSoup(html, "lxml")
    paras = soup.select("p.gb-paragraph") or soup.select("article p, main p")
    rows, cur_country, cur_ccy = [], None, None

    for p in paras:
        text = norm(p.get_text(" ", strip=True))
        if not text: continue

        mc = COUNTRY_RE.match(text)
        if mc:
            country = re.sub(r"\d+$", "", mc.group("country").strip())
            cur_country, cur_ccy = country, mc.group("ccy").strip()
            continue

        mp = PLAN_RE.match(text)
        if mp and cur_country and cur_ccy:
            rows.append({
                "Country": cur_country,
                "Currency": cur_ccy,
                "Plan": standardize_plan(mp.group("size"), mp.group("unit")),
                "Price": parse_numeric_price(mp.group("price").strip()),
                "Price_Display": mp.group("price").strip(),
            })
    return rows

def warn_anomalies(df: pd.DataFrame) -> None:
    expected_plans = {"50 GB", "200 GB", "2 TB", "6 TB", "12 TB"}

    pc = df.groupby("Country")["Plan"].nunique()
    bad = pc[pc != len(expected_plans)]
    if not bad.empty:
        print("\n[WARN] Countries with != 5 plans:\n", bad.to_string())

    missing = df[df["Price"].isna()]
    if not missing.empty:
        print("\n[WARN] Unparsable numeric prices (first 10):\n", missing.head(10).to_string(index=False))

    def mismatch(row):
        hints = CURRENCY_HINTS.get(row["Currency"], [])
        return bool(hints) and not any(h in row["Price_Display"] for h in hints)

    mm = df[df.apply(mismatch, axis=1)]
    if not mm.empty:
        print("\n[WARN] Currency hints do not match header (first 10):\n", mm.head(10).to_string(index=False))

# --- Run ---
html = fetch_html()
rows = parse_all_rows(html)
if not rows:
    txt = OUT_DIR / "icloud_plus_debug.txt"
    txt.write_text(BeautifulSoup(html, "lxml").get_text("\n"), encoding="utf-8")
    raise SystemExit(f"Parsed 0 rows. Debug saved to: {txt}")

df = pd.DataFrame(rows, columns=["Country","Currency","Plan","Price","Price_Display"])
try:
    plan_order = pd.CategoricalDtype(["50 GB","200 GB","2 TB","6 TB","12 TB"], ordered=True)
    df["Plan"] = df["Plan"].astype(plan_order)
except Exception:
    pass
df.sort_values(["Country","Plan"], inplace=True, kind="stable")

warn_anomalies(df)

with pd.ExcelWriter(OUT_XLSX, engine="openpyxl") as w:
    df.to_excel(w, index=False, sheet_name="iCloud+ Prices")
df.to_csv(OUT_CSV, index=False, encoding="utf-8")

print(f"\nRows: {len(df)} | Countries: {df['Country'].nunique()}")
print("Saved:", OUT_XLSX)
print("Also saved:", OUT_CSV)

if DOWNLOAD_FILES and IN_COLAB and not SAVE_TO_DRIVE:
    from google.colab import files
    files.download(str(OUT_XLSX))
    files.download(str(OUT_CSV))