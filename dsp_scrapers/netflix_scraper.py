# -*- coding: utf-8 -*-
"""Netflix_Scraper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y61iZwNUkr_819kLWM6wU5KrLZnRebVI
"""

!pip install -q playwright openpyxl pandas beautifulsoup4
!playwright install --with-deps

import asyncio
import re
import pandas as pd
from bs4 import BeautifulSoup
from playwright.async_api import async_playwright

def extract_price_details(price_text):
    if not price_text or "month" not in price_text.lower():
        return "Unknown", "", price_text

    text = price_text.strip()
    month_split = re.split(r"/\s*month", text, flags=re.IGNORECASE)
    price_part = month_split[0].strip()
    note_part = month_split[1].strip() if len(month_split) > 1 else ""

    number_match = re.search(r"([\d,.]+)", price_part)
    currency_match = re.search(r"([^\d\s,.]+)", price_part)

    amount = number_match.group(1).replace(",", "") if number_match else ""
    currency = currency_match.group(1) if currency_match else "Unknown"

    return currency, amount, note_part

async def process_country(country, page):
    results = []

    try:
        await page.goto("https://help.netflix.com/en/node/24926", timeout=60000)
        await page.wait_for_timeout(2000)

        try:
            await page.click("#onetrust-accept-btn-handler", timeout=3000)
        except:
            pass

        await page.click("div.css-hlgwow", timeout=5000)
        input_box = await page.wait_for_selector('//input[@type="text"]')
        await input_box.fill("")
        await input_box.type(country)
        await input_box.press("Enter")
        await page.wait_for_timeout(3000)

        content = await page.content()
        soup = BeautifulSoup(content, "html.parser")
        pricing_header = soup.find("h3", string=lambda s: s and "Pricing" in s)

        if pricing_header:
            ul = pricing_header.find_next("ul")
            if ul:
                for li in ul.find_all("li"):
                    if ":" in li.text:
                        plan, price_text = li.text.strip().split(":", 1)
                        currency, amount, note = extract_price_details(price_text.strip())
                        results.append({
                            "Country": country,
                            "Plan": plan.strip(),
                            "Price": price_text.strip(),
                            "Currency": currency,
                            "Amount": amount,
                            "Note": note
                        })

        if not results:
            results.append({"Country": country, "Plan": "N/A", "Price": "N/A", "Currency": "", "Amount": "", "Note": ""})

        print(f"‚úÖ {country}")
        return results

    except Exception as e:
        print(f"‚ùå Error: {country} ‚Äî {e}")
        return [{"Country": country, "Plan": "ERROR", "Price": str(e), "Currency": "", "Amount": "", "Note": ""}]

async def main():
    async with async_playwright() as pw:
        browser = await pw.chromium.launch(headless=True)
        context = await browser.new_context()
        page = await context.new_page()

        await page.goto("https://help.netflix.com/en/node/24926")
        await page.wait_for_timeout(3000)
        try:
            await page.click("#onetrust-accept-btn-handler", timeout=3000)
        except:
            pass

        countries_data = await page.evaluate("window.netflix.data.article.allCountries")
        countries = [entry["label"] for entry in countries_data]
        await page.close()

        print(f"üåç Found {len(countries)} countries")

        batch_size = 5
        results = []

        for i in range(0, len(countries), batch_size):
            tasks = []
            pages = []

            for country in countries[i:i+batch_size]:
                tab = await context.new_page()
                pages.append(tab)
                tasks.append(process_country(country, tab))

            batch_results = await asyncio.gather(*tasks)
            for res in batch_results:
                results.extend(res)

            for p in pages:
                await p.close()

        await browser.close()

        df = pd.DataFrame(results)
        df.to_excel("netflix_pricing_by_country.xlsx", index=False, engine="openpyxl")
        print("‚úÖ Saved to 'netflix_pricing_by_country.xlsx'")

await main()

from google.colab import files
files.download("netflix_pricing_by_country.xlsx")